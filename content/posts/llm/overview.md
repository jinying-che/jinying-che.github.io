---
title: "Large Language Model Overview"
date: "2026-01-22T10:11:58+08:00"
tags: ["large language model"]
description: "understand the most basic concept of large language model"
draft: true
---

How to understand the large language model (short as LLM) as an engineer, diving into the fundamentals are not really necessary (of course you can if you are interested), just be able to answer the following basic questions in concise word:

# What's LLM?
At its core, LLM is a next-token predictor. 

Given a sequence of words (tokens), it predicts the most probable next token. By doing this repeatedly, it generates coherent text.

# How does LLM work?
TBD

# How is LLM trained or built?
In short of LLM architecture: **transformer architecture**

## Where is transformer from? 
In short: machine learning -> deep learning -> neural network -> transformer
1. LLM is built on machine learning.
2. Deep learning is a type of machine learning.
3. Neural network is a type of deep learning.
4. Transformer is a type of neural network.

## What is transformer architecture?

![gpt_pipeline](/images/gpt_pipeline.png)
